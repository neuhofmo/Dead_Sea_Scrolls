{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove contamination from SAM/BAM file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook accompanies the paper \"Illuminating Genetic Mysteries of the Dead Sea Scrolls\"\n",
    "#### Author: Moran Neuhof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook describes the code behind the removal of contamination in BAM files.\n",
    "It follows the method described in Figure S4 and in the *\"Filtration of mitochondrial sequences from contaminants\"* section of the STAR methods.\n",
    "The script receives a folder containing BAM files with files, with file names in the following format:\n",
    "```<fragment name>.<species>.<suffix>```  \n",
    "Where:  \n",
    "```\n",
    "suffix = 'mito.e2e.sam'\n",
    "species = one of {'Bos taurus', 'Capra hircus', 'Ovis aries'}, etc.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pysam\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing a CSV file, returning a list of lists.\n",
    "An example for such a CSV file:\n",
    "```\n",
    "dss565,Ovis,Bos\n",
    "dss565,Ovis,Capra\n",
    "dss565,Ovis,Bos+Capra\n",
    "dss565,Bos,Ovis\n",
    "dss565,Bos,Capra\n",
    "dss565,Bos,Ovis+Capra\n",
    "dss565,Capra,Ovis\n",
    "dss565,Capra,Bos\n",
    "dss565,Capra,Ovis+Bos\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv(input_file):\n",
    "    \"\"\"\n",
    "    Parse csv file with the following structure: fragment,organism,other_organsisms\n",
    "    Input: csv file\n",
    "    Outpt: a list of split lines (list of lists)\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r') as infile:\n",
    "        parsed_lines = [line.strip().split(',') for line in infile]\n",
    "    return parsed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bam_file(fragment, organism, other_organisms, bam_path=BAM_PATH):\n",
    "    \"\"\"\n",
    "    Filters reads from fragment.organism which are also present in on of fragment.other_organisms.\n",
    "    The filtered files are saved in bam_path.\n",
    "    \n",
    "    Receives: \n",
    "        fragment:         fragment name\n",
    "        organism:         organism name\n",
    "        other_organisms:  a list of organisms to remove from fragment\n",
    "        bam_path:         a path containing the SAM/BAM files\n",
    "    Returns:\n",
    "        result:           a comma-separated string with of the following fields:\n",
    "                            fragment,organism,#reads,#kept_reads,#removed_reads\n",
    "    \"\"\"\n",
    "\n",
    "    reads_to_remove = []\n",
    "    suffix = \"mito.e2e.sam\" \n",
    "    organism_dict = {\"Bos\": \"Bos_taurus\",\n",
    "                     \"Capra\": \"Capra_hircus\", \n",
    "                     \"Ovis\": \"Ovis_aries\"}\n",
    "    # for organism, organism_full_name in organism_dict.items():\n",
    "    organism_full_name = organism_dict[organism]\n",
    "    filename = os.path.join(bam_path, f\"{fragment}.{organism_full_name}.{suffix}\")\n",
    "    if len(other_organisms) == 1:  # filter only one organism\n",
    "        output_filename = os.path.join(bam_path, f\"{fragment}.{organism_full_name}.mito.cleaned_from_{other_organisms[0]}.bam\")  # saving as BAM\n",
    "    else:  # more than one organism to filter\n",
    "        output_filename = os.path.join(bam_path, f\"{fragment}.{organism_full_name}.mito.cleaned_from_{'_'.join(other_organisms)}.bam\")  # saving as BAM\n",
    "\n",
    "    # now iterate over the two other organisms\n",
    "    for other_organism in other_organisms:\n",
    "        # preparing the other_organism filename\n",
    "        other_organism_full_name = organism_dict[other_organism]\n",
    "        other_organism_filename = os.path.join(bam_path, f\"{fragment}.{other_organism_full_name}.{suffix}\")\n",
    "\n",
    "        # reading the other organism file, looking for reads\n",
    "        with pysam.AlignmentFile(other_organism_filename, \"r\") as other_organism_samfile:\n",
    "            reads_to_remove += [read.qname for read in other_organism_samfile.fetch()]  # compiling a list of read IDs to renmove\n",
    "            \n",
    "\n",
    "    # now open the input and output sam files and remove the reads we don't need:\n",
    "    print(f\"Removing {len(reads_to_remove)} reads from {filename}\")\n",
    "    with pysam.AlignmentFile(filename, \"r\") as input_samfile:\n",
    "        with pysam.AlignmentFile(output_filename, \"wb\", template=input_samfile) as output_bamfile:\n",
    "            read_num = 0  # total reads counter\n",
    "            good_reads = 0  # reads kept counter\n",
    "            # iterating over reads in the original file\n",
    "            for read in input_samfile:\n",
    "                read_num += 1  # counter\n",
    "                if read.qname not in reads_to_remove:  # not removing the read\n",
    "                    output_bamfile.write(read)  \n",
    "                    good_reads += 1  # counter\n",
    "            print(f\"Kept {good_reads} out of {read_num}\")\n",
    "    \n",
    "    # printing result\n",
    "    result = f\"{fragment},{organism},{read_num},{good_reads},{read_num-good_reads}\"\n",
    "    print(f\"Reads written to {output_filename}\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the script requires a path of SAM/BAM files, and a CSV file (infile) in the format above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAM_PATH = # Enter a folder containing the BAM files you wish to filter\n",
    "infile = # Enter CSV file argv[1]  # csv file\n",
    "output_stats_file = \"removed_reads.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment_lines = parse_csv(infile)\n",
    "\n",
    "with open(output_stats_file, 'w') as stats_outfile:\n",
    "    for fragment_line in fragment_lines:  # going over the lines in the CSV file\n",
    "        fragment, organism, other_organisms_str = fragment_line  # unpacking\n",
    "        other_organisms_list = other_organisms_str.split('+')  # treating a case where we filter multiple organisms\n",
    "        print(f\"Filtering {fragment} from {other_organisms_str}:\")\n",
    "        line_to_print = clean_bam_file(fragment, organism, other_organisms_list)  # cleaning file and writing output\n",
    "        print(line_to_print, file=stats_outfile)\n",
    "\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}